{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "clear-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "herbal-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = Path('bc2gm/train_aug2.tsv').read_text().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hawaiian-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALT_ENTITIES = {'PROTEIN': 'GENE', 'CL': 'CELL_TYPE', 'CHEBI': 'CHEMICAL', 'GGP': 'GENE', 'SPECIES': 'TAXON',\n",
    "                'CELLLINE': 'CELL_LINE'}\n",
    "all_tokens = defaultdict(set)\n",
    "named_tokens = []\n",
    "named_tokens_labels = []\n",
    "words = []\n",
    "sentences = []\n",
    "labels = []\n",
    "tags = []\n",
    "\n",
    "complex_token = []\n",
    "complex_token_label = []\n",
    "for line in lines:\n",
    "    pair = line.strip().split('\\t')\n",
    "    if len(pair) == 2:\n",
    "        word, tag = pair\n",
    "        words.append(word)\n",
    "        if tag[2:].upper() in ALT_ENTITIES:\n",
    "            tag = tag[0:2] + ALT_ENTITIES[tag[2:].upper()]\n",
    "        tags.append(tag)\n",
    "        if 'B-' in tag or 'I-' in tag or 'E-' in tag:\n",
    "            complex_token.append(word)\n",
    "            complex_token_label.append(tag)\n",
    "            if 'E-' in tag:\n",
    "                named_tokens.append(complex_token)\n",
    "                named_tokens_labels.append(complex_token_label)\n",
    "                complex_token = []\n",
    "                complex_token_label = []\n",
    "        elif 'S-' in tag:\n",
    "            named_tokens.append([word])\n",
    "            named_tokens_labels.append([tag])\n",
    "        all_tokens[tag].add(word)\n",
    "    else:\n",
    "        sentences.append(words)\n",
    "        labels.append(tags)\n",
    "        words, tags = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "democratic-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = {key: list(value) for key, value in all_tokens.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "racial-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelwise_replace(sentence, labels):\n",
    "    new_sentence = []\n",
    "    for ind, label in enumerate(labels):\n",
    "        p = np.random.uniform()\n",
    "        if p >= 0.5:\n",
    "            new_token = np.random.choice(all_tokens[label])\n",
    "            new_sentence.append(new_token)\n",
    "        else:\n",
    "            new_sentence.append(sentence[ind])\n",
    "    return new_sentence, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "killing-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mention_replace(sentence, labels):\n",
    "    new_sent, new_lab = [], []\n",
    "    for ind, (label, token) in enumerate(zip(labels, sentence)):\n",
    "        if any(letter in label for letter in ['B-', 'S-']):\n",
    "            p = np.random.uniform()\n",
    "            if p >= 0.5:\n",
    "                new_ind = np.random.randint(len(named_tokens))\n",
    "                new_sent.extend(named_tokens[new_ind])\n",
    "                new_lab.extend(named_tokens_labels[new_ind])\n",
    "            else:\n",
    "                if label.startswith('S-'):\n",
    "                    new_sent.append(token)\n",
    "                    new_lab.append(label)\n",
    "                else:\n",
    "                    ind += 1\n",
    "                    while any(letter in label for letter in ['I-', 'E-']):\n",
    "                        new_sent.append(sentence[ind])\n",
    "                        new_lab.append(labels[ind])\n",
    "                        ind += 1\n",
    "        elif any(letter in label for letter in ['I-', 'E-']):\n",
    "            continue\n",
    "        else:\n",
    "            new_sent.append(token)\n",
    "            new_lab.append(label)\n",
    "    return new_sent, new_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vocational-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments_shuffle(sentence, labels):\n",
    "    pieces_tokens, pieces_labels = [], []\n",
    "    prev_label = None\n",
    "    piece_tokens, piece_labels = [], []\n",
    "    for token, label in zip(sentence, labels):\n",
    "        if prev_label == 'O' and label != 'O':\n",
    "            pieces_tokens.append(piece_tokens)\n",
    "            pieces_labels.append(piece_labels)\n",
    "            piece_tokens, piece_labels = [], []\n",
    "        if 'B-' in label or 'I-' in label or 'E-' in label:\n",
    "            piece_tokens.append(token)\n",
    "            piece_labels.append(label)\n",
    "            if 'E-' in label:\n",
    "                pieces_tokens.append(piece_tokens)\n",
    "                pieces_labels.append(piece_labels)\n",
    "                piece_tokens, piece_labels = [], []\n",
    "        elif 'S-' in label:\n",
    "            pieces_tokens.append([token])\n",
    "            pieces_labels.append([label])\n",
    "        else:\n",
    "            piece_tokens.append(token)\n",
    "            piece_labels.append(label)\n",
    "        \n",
    "        prev_label = label\n",
    "    if len(piece_tokens):\n",
    "        pieces_tokens.append(piece_tokens)\n",
    "        pieces_labels.append(piece_labels)\n",
    "    temp = list(zip(pieces_tokens, pieces_labels))\n",
    "    np.random.shuffle(temp)\n",
    "    new_sent, new_lab = zip(*temp)\n",
    "    return [item for sublist in new_sent for item in sublist], [item for sublist in new_lab for item in sublist]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fatal-administration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12573it [1:40:51,  2.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "final_sent, final_lab = [], []\n",
    "for sent, lab in tqdm(zip(sentences, labels)):\n",
    "    final_sent.append(sent)\n",
    "    final_lab.append(lab)\n",
    "    for func in (labelwise_replace, mention_replace, segments_shuffle):\n",
    "        for i in range(3):\n",
    "            new_sent, new_lab = func(sent, lab)\n",
    "            final_sent.append(new_sent)\n",
    "            final_lab.append(new_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "local-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bc2gm/train_aug.tsv', 'a') as file:\n",
    "    for sent, lab in zip(final_sent, final_lab):\n",
    "        for word, label in zip(sent, lab):\n",
    "            file.write(word + '\\t' + label + '\\n')\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-release",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
